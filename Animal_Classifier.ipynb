{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ks3h5IupjSRp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udipta/Animal-Classifier/blob/master/Animal_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "R8GXHu7kzMjQ"
      },
      "cell_type": "markdown",
      "source": [
        "#  **Creating your own Dataset from Google Images**\n",
        "   Inspired By Fastai  Library"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oYK7nOt50VeA"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Get a list of URLs\n",
        "## Search and scroll\n",
        "\n",
        "Go to [Google Images](https://images.google.com/) and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.\n",
        "\n",
        "Scroll down until you see a button that says **Show more results** . All the images you scrolled past are now available to download. To get more, click on the button. Then continue scrolling until you cannot scroll anymore. The maximum number of images Google Images shows is 700.\n",
        "\n",
        "## Download into file\n",
        "\n",
        "Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.\n",
        "\n",
        "Press Ctrl+Shift+J in Windows/Linux and Cmd+Opt+J in Mac for Chrome and Ctrl+Shift+K in Firefox, a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.\n",
        "\n",
        "You will need to get the urls of each of the images. You can do this by running the following commands:\n",
        "\n",
        "\n",
        "\n",
        "```javascript\n",
        "urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n",
        "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wQ6WjY-4GAt7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import all the library's\n",
        "#pip3 install torch torchvision\n",
        "#pip3 install Pillow==4.0.0\n",
        "\n",
        "from tqdm import tqdm ,trange# for progress bar \n",
        "import os,sys,requests \n",
        "from concurrent.futures import ProcessPoolExecutor ,as_completed # Asynchronous Execution\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional  as F\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms ,models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c_Dk4_oYq_iv",
        "outputId": "fc132298-277f-4369-d2e4-60bfd2b762ad",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "cell_type": "code",
      "source": [
        "# Upload the ziped file \n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a89ddf26-13f8-4160-a77a-602bb7f79efe\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a89ddf26-13f8-4160-a77a-602bb7f79efe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving animals.zip to animals.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lfASYDE4tbex",
        "outputId": "c466a643-8c1f-47d3-81db-86690869ccdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip animals.zip\n",
        "!ls -l animals"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  animals.zip\n",
            "replace animals/dog.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: AN\n",
            "  inflating: animals/dog.csv         \n",
            "  inflating: animals/fox.csv         \n",
            "  inflating: animals/lion.csv        \n",
            "  inflating: animals/cat.csv         \n",
            "  inflating: animals/leopard.csv     \n",
            "  inflating: animals/tiger.csv       \n",
            "  inflating: animals/wolf.csv        \n",
            "  inflating: animals/elephant.csv    \n",
            "  inflating: animals/monkey.csv      \n",
            "  inflating: animals/deer.csv        \n",
            "total 760\n",
            "-rw-rw-r-- 1 root root 79860 Mar  9 11:10 cat.csv\n",
            "-rw-rw-r-- 1 root root 74826 Mar  9 11:42 deer.csv\n",
            "-rw-rw-r-- 1 root root 83059 Mar  9 11:09 dog.csv\n",
            "-rw-rw-r-- 1 root root 84165 Mar  9 11:41 elephant.csv\n",
            "-rw-rw-r-- 1 root root 62155 Mar  9 11:12 fox.csv\n",
            "-rw-rw-r-- 1 root root 79299 Mar  9 11:14 leopard.csv\n",
            "-rw-rw-r-- 1 root root 72172 Mar  9 11:13 lion.csv\n",
            "-rw-rw-r-- 1 root root 80821 Mar  9 11:43 monkey.csv\n",
            "-rw-rw-r-- 1 root root 76880 Mar  9 11:14 tiger.csv\n",
            "-rw-rw-r-- 1 root root 64933 Mar  9 11:15 wolf.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sCaeH916o6Lc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_url(url:str, dest:str, overwrite:bool=False, chunk_size=1024*1024, timeout=4):\n",
        "    \"Download `url` to `dest` unless it exists and not `overwrite`.\"\n",
        "    if os.path.exists(dest) and not overwrite: return\n",
        "\n",
        "    u = requests.get(url, stream=True, timeout=timeout)\n",
        "    try: file_size = int(u.headers[\"Content-Length\"])\n",
        "    except: pass\n",
        "        \n",
        "    with open(dest, 'wb') as f:\n",
        "        for chunk in u.iter_content(chunk_size=chunk_size):\n",
        "            f.write(chunk)\n",
        "\n",
        "def download_images(urls:str, dest:Path, max_pics:int=1000, max_workers:int=8, timeout=4,prefix=None,show_progress=True):\n",
        "    \"Download images listed in text file urls to path dest , at most max_pics\"\n",
        "    urls = open(urls).read().strip().split(\"\\n\")[:max_pics] # get all the urls in the list\n",
        "    dest = Path(dest) # get the path of the folder \n",
        "    dest.mkdir(exist_ok=True) # create all the parent and child directory if neccessary. \n",
        "\n",
        "    if max_workers: # use the power of multiprocessing\n",
        "        with ProcessPoolExecutor(max_workers=max_workers) as ex: # use a ProcessPoolExecutor for using pool of process to execute call asynchronously.\n",
        "             # submit schedules the callable and return a Future object on completion. We iterate through all the urls to create Future objects for each url \n",
        "            futures = [ex.submit(download_url, url, dest/f\"{i:08d}.jpg\", timeout=timeout) for i,url in enumerate(urls)]\n",
        "            if show_progress : \n",
        "                for f in tqdm(as_completed(futures), total=len(urls),desc=prefix): pass # show th progress bar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c-GIyV446djY",
        "outputId": "7cbfe615-9291-4bbe-9808-296c60782f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "# get the path for all csv files\n",
        "animalspath = Path(\"animals\")\n",
        "animalspath = [ Path(child) for child in animalspath.iterdir()]\n",
        "animalspath"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('animals/wolf.csv'),\n",
              " PosixPath('animals/elephant.csv'),\n",
              " PosixPath('animals/leopard.csv'),\n",
              " PosixPath('animals/dog.csv'),\n",
              " PosixPath('animals/lion.csv'),\n",
              " PosixPath('animals/tiger.csv'),\n",
              " PosixPath('animals/fox.csv'),\n",
              " PosixPath('animals/cat.csv'),\n",
              " PosixPath('animals/monkey.csv'),\n",
              " PosixPath('animals/deer.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ArS40t5rppb6",
        "outputId": "d3434d9c-bee7-4ad6-8555-b98ec573833a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pprint import pprint \n",
        "all_animals_Name = [re.sub(r\".csv|\\.\\s|\\s*|\\’\" , r\"\", x.name) for x in animalspath] # Get all the animals name from the csv file\n",
        "pprint(all_animals_Name)\n",
        "folder_file = {x:y for x ,y in zip(all_animals_Name , animalspath)} # create a folder name the file name dictionary \n",
        "pprint(folder_file)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wolf',\n",
            " 'elephant',\n",
            " 'leopard',\n",
            " 'dog',\n",
            " 'lion',\n",
            " 'tiger',\n",
            " 'fox',\n",
            " 'cat',\n",
            " 'monkey',\n",
            " 'deer']\n",
            "{'cat': PosixPath('animals/cat.csv'),\n",
            " 'deer': PosixPath('animals/deer.csv'),\n",
            " 'dog': PosixPath('animals/dog.csv'),\n",
            " 'elephant': PosixPath('animals/elephant.csv'),\n",
            " 'fox': PosixPath('animals/fox.csv'),\n",
            " 'leopard': PosixPath('animals/leopard.csv'),\n",
            " 'lion': PosixPath('animals/lion.csv'),\n",
            " 'monkey': PosixPath('animals/monkey.csv'),\n",
            " 'tiger': PosixPath('animals/tiger.csv'),\n",
            " 'wolf': PosixPath('animals/wolf.csv')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mx3NbCz16ua9",
        "outputId": "27fd689a-d28f-4809-c24c-95101f35f385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "# download all the images \n",
        "for folder,file in folder_file.items():\n",
        "    path = Path(\"train\") # create a parent directory   \n",
        "    dest = path/folder # Specific folder for each bird\n",
        "    dest.mkdir(parents=True,exist_ok=True)\n",
        "    download_images(file, dest,prefix=folder,max_workers=16)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wolf: 100%|██████████| 682/682 [00:43<00:00, 10.74it/s]\n",
            "elephant: 100%|██████████| 855/855 [01:34<00:00,  5.75s/it]\n",
            "leopard: 100%|██████████| 832/832 [01:23<00:00,  2.22it/s]\n",
            "dog: 100%|██████████| 839/839 [01:10<00:00,  2.66s/it]\n",
            "lion: 100%|██████████| 753/753 [00:56<00:00, 13.44it/s]\n",
            "tiger: 100%|██████████| 768/768 [00:47<00:00,  3.73it/s]\n",
            "fox: 100%|██████████| 660/660 [00:44<00:00,  8.50it/s]\n",
            "cat: 100%|██████████| 799/799 [00:48<00:00,  1.26s/it]\n",
            "monkey: 100%|██████████| 822/822 [00:54<00:00, 15.21it/s]\n",
            "deer: 100%|██████████| 714/714 [00:49<00:00, 14.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KpivGLyOtfcS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "cbf3820e-a264-4b0e-b476-12cd7f428f97"
      },
      "cell_type": "code",
      "source": [
        "length = lambda iterrator : len(tuple(iterrator))\n",
        "animalsPerClassCount = { (path/folder).name : length((path/folder).iterdir()) for folder,file in folder_file.items() }\n",
        "sorted(animalsPerClassCount.items() , key=lambda x :x[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fox', 648),\n",
              " ('wolf', 677),\n",
              " ('deer', 704),\n",
              " ('lion', 745),\n",
              " ('tiger', 749),\n",
              " ('cat', 780),\n",
              " ('monkey', 815),\n",
              " ('leopard', 821),\n",
              " ('dog', 833),\n",
              " ('elephant', 847)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FBBjtKenyYF1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "def verify_image(file:Path, delete:bool ,dest:Path=None, n_channels:int=3, **kwargs):\n",
        "    \"\"\"Check if the image in `file` exists, can be opend and has `n_channels`. If `delete`, removes it if it fails.\n",
        "        Result is stored in `dest` `img_format` and `kwargs` are passed to PIL.Image.save.\"\"\"\n",
        "    try:\n",
        "        img = PIL.Image.open(file)\n",
        "        assert isinstance(dest, Path), \"You should provide `dest` Path to save resized image\"\n",
        "        if not file.is_file(): return\n",
        "        if n_channels == 3: img = img.convert(\"RGB\")\n",
        "        img.save(file, **kwargs)\n",
        "        img = np.array(img)\n",
        "        img_channels = 1 if len(img.shape) == 2 else img.shape[2]\n",
        "        assert img_channels == n_channels, f\"Image {file} has {img_channels} instead of {n_channels}\"\n",
        "    except Exception as e:\n",
        "        #print(f'{e}')\n",
        "        if delete: file.unlink()\n",
        "\n",
        "def verify_images(path:Path, delete:bool=True, max_workers:int=4 , dest:Path=\".\",n_channels:int=3,**kwargs):\n",
        "    \"\"\"Check if the image in `path` exists, can be opened and has `n_channels`.\n",
        "    If `n_channels` is 3 – it'll try to convert image to RGB. If `delete`, removes it if it fails.\n",
        "    If `max_size` is specifided,\n",
        "    image is resized to the same ratio so that both sizes are less than `max_size`, using `interp`.\n",
        "    Result is stored in `dest`, `ext` forces an extension type, `img_format` and `kwargs` are\n",
        "    passed to PIL.Image.save. Use `max_workers` CPUs.\"\"\"\n",
        "    dest = path/Path(dest)\n",
        "    dest.mkdir(exist_ok=True)\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
        "        files = [Path(file) for file in path.iterdir()]\n",
        "        futures = [ex.submit(verify_image, file, delete=delete,dest=dest, n_channels=n_channels, **kwargs) for file in files]\n",
        "    for f in tqdm(as_completed(futures), total=len(files) , desc=path.name): pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hr87BXiPydTw",
        "outputId": "37a88cdd-d50d-4bc4-edce-aaa55b8a66f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "cell_type": "code",
      "source": [
        "for folder,file in folder_file.items():\n",
        "    path = Path(\"train\")\n",
        "    verify_images(path/folder,delete=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "wolf: 100%|██████████| 677/677 [00:00<00:00, 190688.59it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "elephant: 100%|██████████| 847/847 [00:00<00:00, 208472.24it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 6. Skipping tag 36867\n",
            "  \"Skipping tag %s\" % (size, len(data), tag))\n",
            "leopard: 100%|██████████| 821/821 [00:00<00:00, 215786.66it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "dog: 100%|██████████| 833/833 [00:00<00:00, 210194.64it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "lion: 100%|██████████| 745/745 [00:00<00:00, 205779.16it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "tiger: 100%|██████████| 749/749 [00:00<00:00, 207842.12it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "fox: 100%|██████████| 648/648 [00:00<00:00, 124520.50it/s]\n",
            "cat: 100%|██████████| 780/780 [00:00<00:00, 207034.37it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "monkey: 100%|██████████| 815/815 [00:00<00:00, 100548.81it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n",
            "deer: 100%|██████████| 704/704 [00:00<00:00, 201762.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pid9fWsMygpQ",
        "outputId": "a8fe8391-5ba3-4738-b370-6a78c2238e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "animalsPerClassCountVerify = { (path/folder).name :len([*(path/folder).iterdir()]) for folder,file in folder_file.items() }\n",
        "sorted(animalsPerClassCountVerify.items() , key=lambda x :x[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fox', 614),\n",
              " ('wolf', 650),\n",
              " ('deer', 670),\n",
              " ('tiger', 699),\n",
              " ('lion', 716),\n",
              " ('cat', 742),\n",
              " ('elephant', 775),\n",
              " ('leopard', 779),\n",
              " ('dog', 786),\n",
              " ('monkey', 795)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lnVFrQD06P7A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zYqcR-mb8uHm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLDxLJ_5H8yI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Transfer Learning**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_XtikPyW79GT",
        "outputId": "527f2dcd-d1c2-457d-9efc-a83e5930029c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True) # load the pretrained model\n",
        "num_features = model.fc.in_features # get the no of on_features in last Linear unit\n",
        "print(num_features)\n",
        "## freeze the entire convolution base\n",
        "for param in model.parameters():\n",
        "  param.requires_grad_(False)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "102502400it [00:01, 87869788.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jQyFChlsdiSb",
        "outputId": "9cac0f7a-4bd7-4fbd-b23e-ff39aeddc528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3365
        }
      },
      "cell_type": "code",
      "source": [
        "def create_head(num_features , number_classes ,dropout_prob=0.5 ,activation_func =nn.ReLU):\n",
        "  features_lst = [num_features , num_features//2 , num_features//4]\n",
        "  layers = []\n",
        "  for in_f ,out_f in zip(features_lst[:-1] , features_lst[1:]):\n",
        "    layers.append(nn.Linear(in_f , out_f))\n",
        "    layers.append(activation_func())\n",
        "    layers.append(nn.BatchNorm1d(out_f))\n",
        "    if dropout_prob !=0 : layers.append(nn.Dropout(dropout_prob))\n",
        "  layers.append(nn.Linear(features_lst[-1] , number_classes))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "top_head = create_head(num_features , len(animalsPerClassCount)) # because ten classes\n",
        "model.fc = top_head # replace the fully connected layer\n",
        "\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5)\n",
              "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_K_975NJIKrk",
        "outputId": "5ecbe299-4381-419a-f276-263c775c8bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "transform = transforms.Compose([transforms.Resize((224,224)) , \n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                               ])\n",
        "\n",
        "myDataset = torchvision.datasets.ImageFolder(\"train\" , transform = transform)\n",
        "\n",
        "valid_no  = int(0.2 * len(myDataset))\n",
        "# so divide the data into trainset and testset\n",
        "\n",
        "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
        "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
        "trainLoader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
        "testLoader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)\n",
        "data_loader={\"train\":trainLoader , \"val\":testLoader}\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of trainSet 5781 , len of testSet 1445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wR2i02JdfM5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dA61y40iJVoO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0j9z2QR8Jgva",
        "outputId": "e089db8f-743b-4b74-8ec0-e509e1690d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "sgdr_partial = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.005 )\n",
        "\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Uqcq3wJEKAZk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import trange\n",
        "\n",
        "def train(model , data_loader , criterion , optimizer ,scheduler, num_epochs=5):\n",
        "\n",
        "  for epoch in trange(num_epochs,desc=\"Epochs\"):\n",
        "    result = []\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase==\"train\":     # put the model in training mode\n",
        "        model.train()\n",
        "        scheduler.step()\n",
        "      else:     # put the model in validation mode\n",
        "        model.eval()\n",
        "       \n",
        "      # keep track of training and validation loss\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0.0  \n",
        "      \n",
        "      for data , target in data_loader[phase]:\n",
        "        #load the data and target to respective device\n",
        "        data , target = data.to(device)  , target.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(phase==\"train\"):\n",
        "          #feed the input\n",
        "          output = model(data)\n",
        "          #calculate the loss\n",
        "          loss = criterion(output,target)\n",
        "          preds = torch.argmax(output,1)\n",
        "\n",
        "          if phase==\"train\"  :\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters \n",
        "            loss.backward()\n",
        "            # update the model parameters\n",
        "            optimizer.step()\n",
        "            # zero the grad to stop it from accumulating\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "        running_corrects += torch.sum(preds == target.data).item()\n",
        "        \n",
        "        \n",
        "      epoch_loss = running_loss / len(data_loader[phase].dataset)\n",
        "      epoch_acc = running_corrects / len(data_loader[phase].dataset)\n",
        "\n",
        "      result.append('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "    print(result)\n",
        "          \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V6RTxbvIKmT7",
        "outputId": "3d7ea0f2-8dba-4ccc-9631-c3ce0d651b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "train(model,data_loader , criterion, optimizer,sgdr_partial)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs:  20%|██        | 1/5 [04:25<17:41, 265.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.5904 Acc: 0.8327', 'val Loss: 0.4445 Acc: 0.8782']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|████      | 2/5 [08:52<13:17, 265.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.4433 Acc: 0.8732', 'val Loss: 0.3965 Acc: 0.8927']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|██████    | 3/5 [13:19<08:52, 266.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.3820 Acc: 0.8865', 'val Loss: 0.3847 Acc: 0.8934']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|████████  | 4/5 [17:43<04:25, 265.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.3307 Acc: 0.8979', 'val Loss: 0.3174 Acc: 0.9135']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpochs: 100%|██████████| 5/5 [22:10<00:00, 266.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2834 Acc: 0.9097', 'val Loss: 0.3389 Acc: 0.9073']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lTHBhLIfLGMX",
        "outputId": "eb8b57fc-8b16-46f4-a3c3-73d038b4867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    initial_lr: 0.01\n",
              "    lr: 0.005477457514062632\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rek9McDgUw67"
      },
      "cell_type": "markdown",
      "source": [
        "# Per Class Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_9MthSe-aQ1g",
        "outputId": "296360f8-707f-4f90-fa4b-7bafb88bf42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def perClassAccuracy(model ,classes):\n",
        "  class_correct = np.zeros(len(classes) ,dtype =np.int64 )\n",
        "  class_total = np.zeros_like(class_correct,dtype =np.int64 )\n",
        "  model.eval()\n",
        "  \n",
        "  for data ,target in data_loader[\"val\"]:\n",
        "    data,target =data.to(device) , target.to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "      output =model(data)\n",
        "      preds = torch.argmax(output,1)\n",
        "      for prediction , label in zip(preds , target.data):\n",
        "        if prediction == label:\n",
        "          class_correct[prediction]+=1\n",
        "        class_total[label]+=1\n",
        "  per = np.round((100*class_correct/class_total) ,4)\n",
        "  out = \"\\n\".join([f\"{name} :- {acc} %\" for name ,acc in zip(classes , per)])\n",
        "  return out+\"\\ntotal acc is {0}%\".format(100* sum(class_correct)/sum(class_total))\n",
        "\n",
        "print(perClassAccuracy(model , myDataset.classes))\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat :- 94.4444 %\n",
            "deer :- 93.985 %\n",
            "dog :- 97.3856 %\n",
            "elephant :- 94.0789 %\n",
            "fox :- 81.6176 %\n",
            "leopard :- 87.4214 %\n",
            "lion :- 92.0863 %\n",
            "monkey :- 92.4051 %\n",
            "tiger :- 94.702 %\n",
            "wolf :- 75.8333 %\n",
            "total acc is 90.72664359861592%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "m9bkTpFRVupg"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing the wrong prediction and where exactly model is confused Basically confusion matrix but I don't know how to do that so my new approach"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8Ym8fH7OSaD8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def allwrong_prediction(classes ,model):\n",
        "  test_array =[]\n",
        "  model.eval()\n",
        "  for data ,target in data_loader[\"val\"]:\n",
        "    data,target =data.to(device) , target.to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "      output =model(data)\n",
        "      preds = torch.argmax(output,1)\n",
        "      for prediction , label in zip(preds , target.data):\n",
        "        if prediction != label:\n",
        "            test_array.append([data ,classes[prediction] ,classes[label]])\n",
        "  return test_array\n",
        "\n",
        "s = allwrong_prediction(myDataset.classes , model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eTnKpR4KaCZV"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking what and all wrong predictions model is making  by visualizing this graph it's very clear model is confused peacock"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l2Ssz5wJYLKW",
        "outputId": "041befc0-0699-4007-f808-8ff3e6cbfd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "s_d = [(y,z) for x ,y,z in s]\n",
        "df = pd.DataFrame(s_d)\n",
        "gr = df.groupby([0,1])\n",
        "gr.apply(len).unstack().plot(kind='bar', stacked=True, figsize=(20,10))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb548c46a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHwAAAJpCAYAAADfQyU9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2mCel_rMafqQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving the Model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NRkacNVIaf0d"
      },
      "cell_type": "markdown",
      "source": [
        "When it comes to saving and loading models, there are three core functions to be familiar with:\n",
        "\n",
        "    1. torch.save: Saves a serialized object to disk. This function uses Python’s pickle utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.\n",
        "    \n",
        "    2. torch.load: Uses pickle’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into (see Saving & Loading Model Across Devices).\n",
        "    \n",
        "    3. torch.nn.Module.load_state_dict: Loads a model’s parameter dictionary using a deserialized state_dict. For more information on state_dict, see What is a state_dict?.\n",
        "\n",
        "There are many ways to save the model but we are gonna see the most recommended and safe here we are going to save the model parameters and while loading just load the weights\n",
        "\n",
        "### Saving & Loading a General Checkpoint for Inference and/or Resuming Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uvwZHbbHafxz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save:\n",
        "def createCheckpoint(filename=Path(\"./LatestCheckpoint.pt\")):\n",
        "  checkpoint = {\n",
        "              'epoch': 5,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              \"batch_size\":batch_size,\n",
        "  } # save all important stuff\n",
        "  torch.save(checkpoint , filename)\n",
        "createCheckpoint()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Phl_6nIuafuv",
        "outputId": "8f829507-8fd6-4704-92f6-aaf2ec838a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "# Load\n",
        "'''\n",
        "First Intialize the model and then just load it\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "'''\n",
        "\n",
        "checkpoint = torch.load(Path(\"./LatestCheckpoint.pt\"))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "batch_size = checkpoint['batch_size']\n",
        "\n",
        "model.eval() ## or model.train()\n",
        "optimizer"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    initial_lr: 0.01\n",
              "    lr: 0.005477457514062632\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1lVSjAQ3afm7"
      },
      "cell_type": "markdown",
      "source": [
        "When saving a general checkpoint, to be used for either inference or resuming training, you must save more than just the model’s state_dict. It is important to also save the optimizer’s state_dict, as this contains buffers and parameters that are updated as the model trains. Other items that you may want to save are the epoch you left off on, the latest recorded training loss, external torch.nn.Embedding layers, etc.\n",
        "\n",
        "To save multiple components, organize them in a dictionary and use torch.save() to serialize the dictionary. A common PyTorch convention is to save these checkpoints using the .tar file extension.\n",
        "\n",
        "To load the items, first initialize the model and optimizer, then load the dictionary locally using torch.load(). From here, you can easily access the saved items by simply querying the dictionary as you would expect.\n",
        "\n",
        "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results. If you wish to resuming training, call model.train() to ensure these layers are in training mode."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I8-D7AYHCP0m",
        "outputId": "a0ff6378-166f-4f5e-fde0-0ce02a14ee03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "# save the checkpoint to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp LatestCheckpoint.pt ./gdrive/My\\ Drive/\n",
        "#!cp  ./gdrive/My\\ Drive/LatestCheckpoint.pt ."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HIAOsFZWJQy0"
      },
      "cell_type": "markdown",
      "source": [
        "# LrFinder and One Cycle Policy\n",
        "\n",
        "### Now that our model is giving 88.68 % accuracy let's finetune the model\n",
        "So we train the model in two steps\n",
        "1. First we unfreeze half of the network and use lr finder algo to find optimum lr and then use once cycle policy to train\n",
        "2. unfreeze the entire network and then use lr finder algo to find optimum lr and then use once cycle policy to train.\n",
        "\n",
        "## Let's see how much better we can do with model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wfoFtmRYW2I-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unfreeze(model,percent=0.25):\n",
        "  l = int(np.ceil(len(model._modules.keys())* percent))\n",
        "  l = list(model._modules.keys())[-l:]\n",
        "  print(f\"unfreezing these layer {l}\",)\n",
        "  for name in l:\n",
        "    for params in model._modules[name].parameters():\n",
        "      params.requires_grad_(True)\n",
        "\n",
        "def check_freeze(model):\n",
        "  for name ,layer in model._modules.items():\n",
        "    s = []\n",
        "    for l in layer.parameters():\n",
        "      s.append(l.requires_grad)\n",
        "    print(name ,all(s))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fFy3uWjM6FI8",
        "outputId": "7b731aad-63f4-45d9-ae64-03dcf9441c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# unfreeze half of the model\n",
        "unfreeze(model ,0.20)\n",
        "# check which layer is freezed or not\n",
        "check_freeze(model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unfreezing these layer ['layer4', 'avgpool', 'fc']\n",
            "conv1 False\n",
            "bn1 False\n",
            "relu True\n",
            "maxpool True\n",
            "layer1 False\n",
            "layer2 False\n",
            "layer3 False\n",
            "layer4 True\n",
            "avgpool True\n",
            "fc True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ks3h5IupjSRp"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Finder\n",
        " Basically in simple terms learning rate finder starts the lr from base lr which is usally a small value , eventually increasing lr using some anneal function.\n",
        " \n",
        " Different type of anneal functions are \n",
        " 1. Linear\n",
        " 2. Exponential\n",
        " 3. Cosine\n",
        " \n",
        "For example :- suppose base lr is 0.001 and max lr is 5 and no of iteration is 20 \n",
        " $$\n",
        " no\\ of\\ iteration = \\frac{training\\ data}{batch\\ size}\n",
        " $$\n",
        " \n",
        " Then basically annneal function helps the lr to go from base lr to max lr in steps and thus generating a loss graph which after visualizing we have to pick the lr from the graph where loss just start decreasing.\n",
        " \n",
        " we in this notebook will implement Linear and exponential annealing function."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_eHHQnTzxe_D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearScheduler(lr_scheduler._LRScheduler):\n",
        "    \"\"\"Linearly increases the learning rate between two boundaries over a number of iterations.\"\"\"\n",
        "    def __init__(self, optimizer, end_lr, num_iter):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(LinearScheduler,self).__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        # increement one by one\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        # get the ratio\n",
        "        pct = curr_iter / self.num_iter\n",
        "        # calculate lr with this formulae start + pct * (end-start)\n",
        "        return [base_lr + pct * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class ExponentialScheduler(lr_scheduler._LRScheduler):\n",
        "    \"\"\"Exponentially increases the learning rate between two boundaries over a number of iterations.\"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialScheduler,self).__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        pct = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** pct for base_lr in self.base_lrs]\n",
        "      \n",
        "class CosineScheduler(lr_scheduler._LRScheduler):\n",
        "    \"\"\"Cosine increases the learning rate between two boundaries over a number of iterations.\"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(CosineScheduler,self).__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        pct = curr_iter / self.num_iter\n",
        "        cos_out = np.cos(np.pi * pct) + 1\n",
        "        return [self.end_lr + (base_lr - self.end_lr )/2 *cos_out for base_lr in self.base_lrs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BQwBWKs0CaRm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LRFinder:\n",
        "  \n",
        "  def __init__(self, model  , optimizer , criterion ,start_lr=1e-7, device=None):\n",
        "    \n",
        "    self.model = model\n",
        "    # Move the model to the proper device\n",
        "    self.optimizer = optimizer\n",
        "    self.criterion = criterion\n",
        "    \n",
        "    ## save the model intial dict\n",
        "    self.save_file = Path(\"tmpfile\")\n",
        "    torch.save(self.model , self.save_file)    \n",
        "    if device is None:\n",
        "      self.device = next(model.parameters()).device\n",
        "    else:\n",
        "      self.device = device\n",
        "    self.model.to(self.device)\n",
        "    \n",
        "    self.history = {\"lr\":[] , \"losses\":[]}\n",
        "    for l in self.optimizer.param_groups:\n",
        "      l[\"initial_lr\"]=start_lr\n",
        "    \n",
        "    \n",
        "  def reset(self):\n",
        "    \"\"\" Resets the model to intial state \"\"\"\n",
        "    self.model = torch.load(self.save_file)\n",
        "    self.model.train()\n",
        "    self.save_file.unlink()\n",
        "    return self.model\n",
        "    \n",
        "  def calculateSmmothingValue(self ,beta):\n",
        "    n ,mov_avg=0,0\n",
        "    while True :\n",
        "      n+=1\n",
        "      value = yield\n",
        "      mov_avg = beta*mov_avg +(1-beta)*value\n",
        "      smooth = mov_avg / (1 - beta **n )\n",
        "      yield smooth\n",
        "    \n",
        "  def lrfind(self, trainLoader,end_lr=10,num_iter=150,step_mode=\"exp\", loss_smoothing_beta=0.99, diverge_th=5): \n",
        "        \"\"\"\n",
        "         Performs the lrfind test\n",
        "\n",
        "         Arguments:\n",
        "            trainLoader : The data loader\n",
        "            end_lr :  The maximum lr\n",
        "            num_iter : Max iteratiom\n",
        "            step_mode : The anneal function by default `exp` but can be either `linear` or `cos`\n",
        "            smooth_f : The loss smoothing factor, value should be between [0 , 1[\n",
        "            diverge_th: The max loss value after which training should be stooped\n",
        "        \"\"\"\n",
        "              # Reset test results\n",
        "        self.history = {\"lr\": [], \"losses\": []}\n",
        "        self.best_loss = None\n",
        "        self.smoothner = self.calculateSmmothingValue(loss_smoothing_beta)\n",
        "        \n",
        "        if step_mode.lower()==\"exp\":\n",
        "          lr_schedule = ExponentialScheduler(self.optimizer , end_lr  , num_iter,)\n",
        "        elif step_mode.lower()==\"cos\":\n",
        "          lr_schedule = CosineScheduler(self.optimizer , end_lr  , num_iter)\n",
        "        elif step.mode.lower()==\"linear\":\n",
        "          lr_schedule = LinearScheduler(self.optimizer , end_lr  , num_iter)\n",
        "        else:\n",
        "          raise ValueError(f\"expected mode is either {exp , cos ,linear} got {step_mode}\")\n",
        "        \n",
        "        if 0 < loss_smoothing_beta >=1:\n",
        "          raise ValueError(\"smooth_f is outside the range [0, 1[\")\n",
        "        \n",
        "        iterator = iter(trainLoader)\n",
        "        for each_iter in range(num_iter):\n",
        "          try:\n",
        "            data , target = next(iterator)\n",
        "          except StopIteration:\n",
        "            iterator = iter(trainLoader)\n",
        "            data , target = next(iterator)\n",
        "         \n",
        "          loss = self._train_batch(data , target)\n",
        "          \n",
        "          # Update the learning rate\n",
        "          lr_schedule.step()\n",
        "          self.history[\"lr\"].append(lr_schedule.get_lr()[0])\n",
        "          # Track the best loss and smooth it if smooth_f is specified\n",
        "          if each_iter == 0:\n",
        "              self.best_loss = loss\n",
        "          else:\n",
        "              next(self.smoothner)\n",
        "              self.best_loss = self.smoothner.send(loss)\n",
        "              if loss < self.best_loss:\n",
        "                  self.best_loss = loss\n",
        "\n",
        "          # Check if the loss has diverged; if it has, stop the test\n",
        "          self.history[\"losses\"].append(loss)\n",
        "          if loss > diverge_th * self.best_loss:\n",
        "              print(\"Stopping early, the loss has diverged\")\n",
        "              break\n",
        "\n",
        "        print(\"Learning rate search finished. See the graph with {finder_name}.plot()\")            \n",
        "  \n",
        "  def _train_batch(self,data,target):\n",
        "    # set to training mode\n",
        "    self.model.train()\n",
        "    #load data to device\n",
        "    data ,target = data.to(self.device) ,target.to(self.device)\n",
        "    \n",
        "    #forward pass\n",
        "    self.optimizer.zero_grad()\n",
        "    output = self.model(data)\n",
        "    loss = self.criterion(output,target)\n",
        "    \n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss.item()\n",
        "  \n",
        "  def plot(self):\n",
        "    losses = self.history[\"losses\"]\n",
        "    lr = self.history[\"lr\"]\n",
        "    plt.semilogx(lr,losses)\n",
        "    plt.xlabel(\"Learning rate\")\n",
        "    plt.ylabel(\"Losses \")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2XJPqcmzgTNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d1ace42-ce14-4dc2-ed51-423903a277dc"
      },
      "cell_type": "code",
      "source": [
        "lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
        "lr_finder.lrfind(data_loader[\"train\"], end_lr=10, step_mode=\"exp\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ooVHCEJUgwIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "e887696d-ccd6-43e1-e691-416c051128b4"
      },
      "cell_type": "code",
      "source": [
        "lr_finder.plot()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFcCAYAAADyAHbiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kfGe5SJlgwQ8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model= lr_finder.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N_5ZVA93CpVv"
      },
      "cell_type": "markdown",
      "source": [
        "## [One Cycle Policy](https://sgugger.github.io/the-1cycle-policy.html)\n",
        "one cycle policy is a technique in which the training process in divided into two section in first half the momentum is decreased and lr is increased and in other section we do the vice- versa\n",
        "\n",
        "While using Adam we use beta1 property as momentum\n",
        "\n",
        "But still there is this big question why one cycle policy .\n",
        "1. This techniques helps model to converge faster.\n",
        "2. Helps to take the model out of saddle point\n",
        "3. Helps to stablilize the model by taking it out from local minima or sharp global minima instead getting the model into more flat surface on that curve.\n",
        "\n",
        "![](https://sgugger.github.io/images/art5_full_schedule.png)\n",
        "\n",
        "This times let's see another approach of modifying lr and momentum"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Qgar8cBUBYJN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Stepper():\n",
        "    \"Used to \\\"step\\\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`\"\n",
        "    \n",
        "    def __init__(self, val, n_iter:int, func):\n",
        "        self.start,self.end = val\n",
        "        self.n_iter = max(1,n_iter)\n",
        "        self.func = func\n",
        "        self.n = 0\n",
        "\n",
        "    def step(self):\n",
        "        \"Return next value along annealed schedule.\"\n",
        "        self.n += 1\n",
        "        return self.func(self.start, self.end, self.n/self.n_iter)\n",
        "\n",
        "    @property\n",
        "    def is_done(self):\n",
        "        \"Return `True` if schedule completed.\"\n",
        "        return self.n >= self.n_iter\n",
        "    \n",
        "# Annealing functions\n",
        "def annealing_no(start, end, pct):\n",
        "    \"No annealing, always return `start`.\"\n",
        "    return start\n",
        "  \n",
        "def annealing_linear(start, end, pct):\n",
        "    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
        "    return start + pct * (end-start)\n",
        "  \n",
        "def annealing_exp(start, end, pct):\n",
        "    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
        "    return start * (end/start) ** pct\n",
        "\n",
        "def annealing_cos(start, end, pct):\n",
        "    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
        "    cos_out = np.cos(np.pi * pct) + 1\n",
        "    return end + (start-end)/2 * cos_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lAgyAWG07XpO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class OneCyclePolicy:\n",
        "  \n",
        "  def __init__(self,model , optimizer , criterion ,num_iteration,num_epochs,max_lr, momentum = (0.95,0.85) , div_factor=25 , pct_start=0.4, device=None ):\n",
        "    \n",
        "    self.model =model\n",
        "    self.optimizer = optimizer\n",
        "    self.criterion = criterion\n",
        "    self.num_epochs = num_epochs\n",
        "    if device is None:\n",
        "      self.device = next(model.parameters()).device\n",
        "    else:\n",
        "      self.device = device\n",
        "      \n",
        "    n = num_iteration * self.num_epochs\n",
        "    a1 = int(n*pct_start)\n",
        "    a2 = n-a1\n",
        "    self.phases = ((a1 , annealing_linear) , (a2 , annealing_cos))\n",
        "    min_lr = max_lr/div_factor\n",
        "    self.lr_scheds = self.steps((min_lr,max_lr) , (max_lr,min_lr/1e4))\n",
        "    self.mom_scheds =self.steps(momentum , momentum[::-1])\n",
        "    self.idx_s = 0\n",
        "    self.update_lr_mom(self.lr_scheds[0].start,self.mom_scheds[0].start)\n",
        "  \n",
        "  def steps(self, *steps):\n",
        "      \"Build anneal schedule for all of the parameters.\"\n",
        "      return [Stepper(step, n_iter, func=func)for (step,(n_iter,func)) in zip(steps, self.phases)]\n",
        "\n",
        "  def train(self, trainLoader , validLoader ):\n",
        "    self.model.to(self.device)\n",
        "    data_loader = {\"train\":trainLoader , \"val\":validLoader}\n",
        "    for epoch in tqdm(range(self.num_epochs),desc=\"Epochs\"):\n",
        "      result = []\n",
        "      for phase in ['train', 'val']:\n",
        "        if phase==\"train\":     # put the model in training mode\n",
        "          model.train()\n",
        "        else:     # put the model in validation mode\n",
        "          model.eval()\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0  \n",
        "\n",
        "        for data , target in data_loader[phase]:\n",
        "          #load the data and target to respective device\n",
        "          data , target = data.to(device)  , target.to(device)\n",
        "\n",
        "          with torch.set_grad_enabled(phase==\"train\"):\n",
        "            #feed the input\n",
        "            output = self.model(data)\n",
        "            #calculate the loss\n",
        "            loss = self.criterion(output,target)\n",
        "            preds = torch.argmax(output,1)\n",
        "\n",
        "            if phase==\"train\"  :\n",
        "              # backward pass: compute gradient of the loss with respect to model parameters \n",
        "              loss.backward()\n",
        "              # update the model parameters\n",
        "              self.optimizer.step()\n",
        "              # zero the grad to stop it from accumulating\n",
        "              self.optimizer.zero_grad()\n",
        "            \n",
        "              self.update_lr_mom(self.lr_scheds[self.idx_s].step() ,self.mom_scheds[self.idx_s].step() )\n",
        "\n",
        "              if self.lr_scheds[self.idx_s].is_done:\n",
        "                self.idx_s += 1\n",
        "          \n",
        "          # statistics\n",
        "          running_loss += loss.item() * data.size(0)\n",
        "          running_corrects += torch.sum(preds == target.data).item()\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / len(data_loader[phase].dataset)\n",
        "        epoch_acc = running_corrects/ len(data_loader[phase].dataset)\n",
        "\n",
        "        result.append('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "      print(result)\n",
        "\n",
        "  def update_lr_mom(self,lr=0.001,mom=0.99):\n",
        "    for l in self.optimizer.param_groups:\n",
        "      l[\"lr\"]=lr\n",
        "      if isinstance(self.optimizer , ( torch.optim.Adamax,torch.optim.Adam)):\n",
        "          l[\"betas\"] = ( mom, 0.999)\n",
        "      elif isinstance(self.optimizer, torch.optim.SGD):\n",
        "          l[\"momentum\"] =mom\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eg1skyubgp7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05c0148b-41ac-4e9b-e083-a41dc3307d18"
      },
      "cell_type": "code",
      "source": [
        "len(trainLoader)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xoIHaT8t7YDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "1efd0540-bdfc-4590-b8b4-a335763ab6fd"
      },
      "cell_type": "code",
      "source": [
        "fit_one_cycle = OneCyclePolicy(model ,optimizer , criterion,num_iteration=len(trainLoader)  , num_epochs =12 , max_lr =1e-4 ,device=device)\n",
        "fit_one_cycle.train(trainLoader,testLoader)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epochs:  12%|█▎        | 1/8 [04:37<32:24, 277.77s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2475 Acc: 0.9246', 'val Loss: 0.3317 Acc: 0.9100']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  25%|██▌       | 2/8 [09:17<27:49, 278.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2447 Acc: 0.9216', 'val Loss: 0.4021 Acc: 0.9073']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  38%|███▊      | 3/8 [13:57<23:14, 278.85s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2479 Acc: 0.9216', 'val Loss: 0.3110 Acc: 0.9093']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  50%|█████     | 4/8 [18:37<18:36, 279.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2518 Acc: 0.9280', 'val Loss: 0.3662 Acc: 0.9121']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  62%|██████▎   | 5/8 [23:17<13:58, 279.55s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2501 Acc: 0.9248', 'val Loss: 0.4209 Acc: 0.9114']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  75%|███████▌  | 6/8 [27:59<09:20, 280.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2379 Acc: 0.9263', 'val Loss: 0.4174 Acc: 0.9073']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:  88%|████████▊ | 7/8 [32:39<04:40, 280.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2457 Acc: 0.9239', 'val Loss: 0.3356 Acc: 0.9087']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 100%|██████████| 8/8 [37:20<00:00, 280.42s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['train Loss: 0.2582 Acc: 0.9209', 'val Loss: 0.3952 Acc: 0.9073']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "B-MbABoJjVDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f7c25ef5-5b60-4da2-8bd0-67dee63509d0"
      },
      "cell_type": "code",
      "source": [
        "print(perClassAccuracy(model , myDataset.classes))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat :- 91.6667 %\n",
            "deer :- 93.2331 %\n",
            "dog :- 98.0392 %\n",
            "elephant :- 96.0526 %\n",
            "fox :- 83.0882 %\n",
            "leopard :- 88.0503 %\n",
            "lion :- 89.9281 %\n",
            "monkey :- 93.6709 %\n",
            "tiger :- 94.702 %\n",
            "wolf :- 75.0 %\n",
            "total acc is 90.72664359861592%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RLhIDyk8kBmD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "createCheckpoint(filename=Path(\"./latestCheckpoint90_59\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f1J9kc1tktI4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp latestCheckpoint90_59 gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bOrmcapqk4T8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y2zOz1_PmR71"
      },
      "cell_type": "markdown",
      "source": [
        "## So after getting 90 accuracy the model can be finetunned more and we stopped here because this the accuracy I obtained using Fast.ai v1 library\n",
        "1. By unfreezing more layers and training them\n",
        "2. By performing Data Augmentation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lHr-4E238nXW"
      },
      "cell_type": "markdown",
      "source": [
        "# Additional Resources\n",
        "\n",
        "https://cs231n.github.io/transfer-learning/\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/index.html\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jT0FW-N4mKrw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BjJc2jGigKcd"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment \n",
        " # Improve model to 93% accuracy and share the code"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YO00dXcEgOuo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}